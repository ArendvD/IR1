{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter Notebook contains the first project for Information Retrieval 1 taught at the UvA. Code is made by Oscar Ligthart, Nicole Ferreira Silverio and Arend van Dormalen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER TO THEORETICAL QUESTION 1A\n",
    "\n",
    "The chance of a type 1 error ($\\alpha$) increases each time an experiment is repeated, if it's not corrected. The new $\\alpha$ is the original $\\alpha$ multiplied by the amount of times the experiment has been conducted.\n",
    "In other words; if an experiment is repeated _m_ times, the chance of a type 1 error is _m_ $\\cdot  \\alpha$\n",
    "\n",
    "ANSWER TO THEORETICAL QUESTION 2\n",
    "\n",
    "Assume two ranked lists created by two different rankers. List $l1$ contains documents $d1$, $d2$ and $d3$ in that order. List $l2$ contains documents $d2$, $d3$ and $d4$ in that order. Now assume that the only relevant document is $d3$, which will therefore be clicked on most often. From our judgment, it is obvious that $l2$ is the most relevant list as it has placed $d3$ on a higher position. However, in Team Draft Interleaving, these algorithms will be evaluated as having equal performance.\n",
    "\n",
    "In this situation, $d3$ will always be the third item on the interleaved list. After the first coin flip, $d2$ will be removed from $l1$ as this document has already been supplied by $l2$.  At the second coin flip, $d3$ will be the next document for both lists. This causes the relevance for both lists to be the same, as they now both have the same chance of supplying the only relevant document to the interleaved list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "metadata": {
    "collapsed": true
   },
=======
   "metadata": {},
>>>>>>> 86f8799d6da00a9cbbd1217c208d27e821f9b7a9
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# first get the sequence options\n",
    "relevance = ['N', 'R', 'HR']\n",
    "options = list(itertools.product(relevance, repeat = 5))\n",
    "\n",
    "# create all possible pairs in sequence options\n",
    "pair_index = list(itertools.permutations(range(len(options)), 2))\n",
    "\n",
    "\n",
    "pairs = []\n",
    "\n",
    "for temp_pair in pair_index:\n",
    "    pairs.append([options[temp_pair[0]], options[temp_pair[1]]])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_precision(ranking):\n",
    "    rel = 0\n",
    "    AP_numerator = 0\n",
    "    # get amount of relevant documents\n",
    "    for i, doc in enumerate(ranking):\n",
    "        if doc == 'R' or doc == 'HR':\n",
    "            rel += 1\n",
    "            AP_numerator += rel/(i+1)\n",
    "            \n",
    "    return rel, AP_numerator\n",
    "\n",
    "# new dict for average precision for both P and E (key is pair, value is average precisions))\n",
    "AP_results = {}\n",
    "\n",
    "# get precision for all pairs\n",
    "for pair in pairs:\n",
    "    # first calculate numerator for average precision for P\n",
    "    P = pair[0]    \n",
    "    P_rel, P_AP_numerator = get_average_precision(P)\n",
    " \n",
    "    # now calculate numerator for average precision for E\n",
    "    E = pair[1]\n",
    "    E_rel, E_AP_numerator = get_average_precision(E)\n",
    "\n",
    "    # get total number of relevant documents returned from query\n",
    "    total_rel = P_rel + E_rel\n",
    "    \n",
    "    # calculate average precision for both P and E\n",
    "    P_AP = P_AP_numerator/total_rel\n",
    "    E_AP = E_AP_numerator/total_rel\n",
    "    \n",
    "    # store results in a dict\n",
    "    AP_results[(P,E)] = (P_AP, E_AP)\n",
    "\n",
    "#for value in AP_results.values():\n",
    "#    print(value)\n",
    "    \n",
    "#print(len(AP_results.values()))\n",
    "print(len(pairs))\n",
    "\n",
    "####### NOW GET DELTA MEASURES #########\n",
    "AP_delta_values = []\n",
    "for key, value in AP_results.items():\n",
    "    if value[1] > value[0]:\n",
    "        delta_value = value[1] - value[0]\n",
    "        AP_delta_values.append(delta_value)\n",
    "\n",
    "\n",
    "print(len(AP_delta_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### nDCG cell #####\n",
    "def get_nDCG(ranking):\n",
    "    DCG = 0    \n",
    "    # loop through ranking\n",
    "    for i, rank in enumerate(ranking):\n",
    "        # decide what the relative rank is\n",
    "        if rank == 'HR':\n",
    "            rel_r = 2\n",
    "        elif rank == 'R':\n",
    "            rel_r = 1\n",
    "        elif rank == 'N':\n",
    "            rel_r = 0\n",
    "        \n",
    "        # use following function to calculate DCG\n",
    "        DCG += (2**rel_r - 1)/(np.log2(1+(i+1)))\n",
    "    \n",
    "    return DCG\n",
    "\n",
    "# new dict for average precision for both P and E (key is pair, value is average precisions))\n",
    "nDCG_results = {}\n",
    "\n",
    "# get nDCG for all pairs\n",
    "for pair in pairs:    \n",
    "    # first for P\n",
    "    P = pair[0]\n",
    "    P_DCG = get_nDCG(P)\n",
    "    \n",
    "    # then for E\n",
    "    E = pair[1]\n",
    "    E_DCG = get_nDCG(E)\n",
    "    \n",
    "    nDCG_results[(P,E)] = (P_DCG, E_DCG)\n",
    "    \n",
    "##### NOW GET THE DELTA MEASURES #####\n",
    "nDCG_delta_values = []\n",
    "for key, value in nDCG_results.items():\n",
    "    if value[1] > value[0]:\n",
    "        delta_value = value[1] - value[0]\n",
    "        nDCG_delta_values.append(delta_value)\n",
    "\n",
    "\n",
    "print(len(nDCG_delta_values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### ERR cell #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Balanced Interleaving #####\n",
    "\n",
    "# Select a pair\n",
    "pair = pairs[random.randint(0,len(pairs))]\n",
    "\n",
    "# Flip a coin, assign winning and losing\n",
    "# P = pair[0], E = pair[1]\n",
    "coin_winner = random.randint(0,1)\n",
    "winner = pair[coin_winner]\n",
    "loser = pair[1 - coin_winner]\n",
    "\n",
    "# initiate lists\n",
    "resulting_list = []\n",
    "origin_list = []\n",
    "\n",
    "# iterate through lists, fill up results and origin list\n",
    "for i in range(len(winner)):\n",
    "    resulting_list.append(winner[i])\n",
    "    origin_list.append(coin_winner)\n",
    "    resulting_list.append(loser[i])\n",
    "    origin_list.append(1-coin_winner)\n",
    "print(\"Result:\",resulting_list)\n",
    "print(\"From lists:\",origin_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
