{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter Notebook contains the first project for Information Retrieval 1 taught at the UvA. Code is made by Oscar Ligthart, Nicole Ferreira Silverio and Arend van Dormalen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER TO THEORETICAL QUESTION 1A\n",
    "\n",
    "The chance of a type 1 error ($\\alpha$) increases each time an experiment is repeated, if it's not corrected. The new $\\alpha$ for _m_ experiments is $1 − (1 − \\alpha)^m ≈ m\\alpha$.\n",
    "\n",
    "ANSWER TO THEORETICAL QUESTION 2\n",
    "\n",
    "Assume two ranked lists created by two different rankers. List $l1$ contains documents $d1$, $d2$ and $d3$ in that order. List $l2$ contains documents $d2$, $d3$ and $d4$ in that order. Now assume that the only relevant document is $d3$, which will therefore be clicked on most often. From our judgment, it is obvious that $l2$ is the most relevant list as it has placed $d3$ on a higher position. However, in Team Draft Interleaving, these algorithms will be evaluated as having equal performance.\n",
    "\n",
    "In this situation, $d3$ will always be the third item on the interleaved list. After the first coin flip, $d2$ will be removed from $l1$ as this document has already been supplied by $l2$.  At the second coin flip, $d3$ will be the next document for both lists. This causes the relevance for both lists to be the same, as they now both have the same chance of supplying the only relevant document to the interleaved list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "\n",
    "# first get the sequence options\n",
    "relevance = ['N', 'R', 'HR']\n",
    "options = list(itertools.product(relevance, repeat = 5))\n",
    "\n",
    "# create all possible pairs in sequence options\n",
    "pair_index = list(itertools.permutations(range(len(options)), 2))\n",
    "\n",
    "\n",
    "pairs = []\n",
    "\n",
    "for temp_pair in pair_index:\n",
    "    pairs.append([options[temp_pair[0]], options[temp_pair[1]]])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_precision(ranking):\n",
    "    rel = 0\n",
    "    AP_numerator = 0\n",
    "    # get amount of relevant documents\n",
    "    for i, doc in enumerate(ranking):\n",
    "        if doc == 'R' or doc == 'HR':\n",
    "            rel += 1\n",
    "            AP_numerator += rel/(i+1)\n",
    "            \n",
    "    return rel, AP_numerator\n",
    "\n",
    "# new dict for average precision for both P and E (key is pair, value is average precisions))\n",
    "AP_results = {}\n",
    "\n",
    "# get precision for all pairs\n",
    "for pair in pairs:\n",
    "    # first calculate numerator for average precision for P\n",
    "    P = pair[0]    \n",
    "    P_rel, P_AP_numerator = get_average_precision(P)\n",
    " \n",
    "    # now calculate numerator for average precision for E\n",
    "    E = pair[1]\n",
    "    E_rel, E_AP_numerator = get_average_precision(E)\n",
    "\n",
    "    # get total number of relevant documents returned from query\n",
    "    total_rel = P_rel + E_rel\n",
    "    \n",
    "    # calculate average precision for both P and E\n",
    "    P_AP = P_AP_numerator/total_rel\n",
    "    E_AP = E_AP_numerator/total_rel\n",
    "    \n",
    "    # store results in a dict\n",
    "    AP_results[(P,E)] = (P_AP, E_AP)\n",
    "\n",
    "#for value in AP_results.values():\n",
    "#    print(value)\n",
    "    \n",
    "#print(len(AP_results.values()))\n",
    "print(len(pairs))\n",
    "\n",
    "####### NOW GET DELTA MEASURES #########\n",
    "AP_delta_values = []\n",
    "for key, value in AP_results.items():\n",
    "    if value[1] > value[0]:\n",
    "        delta_value = value[1] - value[0]\n",
    "        AP_delta_values.append(delta_value)\n",
    "\n",
    "print(len(AP_delta_values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### nDCG cell #####\n",
    "def get_nDCG(ranking):\n",
    "    DCG = 0\n",
    "    \n",
    "    # loop through ranking\n",
    "    for i, rank in enumerate(ranking):\n",
    "        # decide what the relative rank is\n",
    "        if rank == 'HR':\n",
    "            rel_r = 2\n",
    "        elif rank == 'R':\n",
    "            rel_r = 1\n",
    "        elif rank == 'N':\n",
    "            rel_r = 0\n",
    "        \n",
    "        DCG += (2**rel_r - 1)/(np.log2(1+(i+1)))\n",
    "    \n",
    "    return DCG\n",
    "\n",
    "# new dict for average precision for both P and E (key is pair, value is average precisions))\n",
    "nDCG_results = {}\n",
    "\n",
    "# get nDCG for all pairs\n",
    "for pair in pairs:    \n",
    "    # first for P\n",
    "    P = pair[0]\n",
    "    P_DCG = get_nDCG(P)\n",
    "    \n",
    "    # then for E\n",
    "    E = pair[1]\n",
    "    E_DCG = get_nDCG(E)\n",
    "    \n",
    "    nDCG_results[(P,E)] = (P_DCG, E_DCG)\n",
    "    \n",
    "##### NOW GET THE DELTA MEASURES #####\n",
    "nDCG_delta_values = []\n",
    "for key, value in nDCG_results.items():\n",
    "    if value[1] > value[0]:\n",
    "        delta_value = value[1] - value[0]\n",
    "        nDCG_delta_values.append(delta_value)\n",
    "\n",
    "\n",
    "print(len(nDCG_delta_values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### ERR cell #####\n",
    "\n",
    "def get_ERR(ranking):\n",
    "    \n",
    "    ERR = 0\n",
    "    p = 1\n",
    "    max_rel = 2\n",
    "    \n",
    "    # loop through ranking\n",
    "    for i, rank in enumerate(ranking):\n",
    "        \n",
    "        # start at second rank\n",
    "        if i != 0:\n",
    "            \n",
    "            # decide what the relative rank is\n",
    "            if rank == 'HR':\n",
    "                rel_r = 2\n",
    "            elif rank == 'R':\n",
    "                rel_r = 1\n",
    "            elif rank == 'N':\n",
    "                rel_r = 0\n",
    "\n",
    "            # Calculate R with the mapping function\n",
    "            R = (2**rel_r - 1)/(2**max_rel)\n",
    "\n",
    "            # Modify ERR value\n",
    "            ERR += p * (R/i)\n",
    "\n",
    "            # Modify p\n",
    "            p = p*(1-R)\n",
    "    \n",
    "    return ERR\n",
    "\n",
    "# new dict for ERR values for both P and E (key is pair, value is ERR value))\n",
    "ERR_results = {}\n",
    "\n",
    "# get ERR for all pairs\n",
    "for pair in pairs:\n",
    "    \n",
    "    # first for P\n",
    "    P = pair[0]\n",
    "    P_ERR = get_ERR(P)\n",
    "    \n",
    "    # then for E\n",
    "    E = pair[1]\n",
    "    E_ERR = get_ERR(E)\n",
    "    \n",
    "    ERR_results[(P,E)] = (P_ERR, E_ERR)\n",
    "    \n",
    "##### NOW GET THE DELTA MEASURES #####\n",
    "ERR_delta_values = []\n",
    "for key, value in ERR_results.items():\n",
    "    if value[1] > value[0]:\n",
    "        delta_value = value[1] - value[0]\n",
    "        ERR_delta_values.append(delta_value)\n",
    "\n",
    "\n",
    "print(len(ERR_delta_values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Balanced Interleaving #####\n",
    "\n",
    "# Select a pair\n",
    "pair = pairs[random.randint(0,len(pairs))]\n",
    "\n",
    "# Flip a coin, assign winning and losing\n",
    "# P = pair[0], E = pair[1]\n",
    "coin_winner = random.randint(0,1)\n",
    "winner = pair[coin_winner]\n",
    "loser = pair[1 - coin_winner]\n",
    "\n",
    "# initiate lists\n",
    "resulting_list = []\n",
    "origin_list = []\n",
    "\n",
    "# iterate through lists, fill up results and origin list\n",
    "for i in range(len(winner)):\n",
    "    resulting_list.append(winner[i])\n",
    "    origin_list.append(coin_winner)\n",
    "    resulting_list.append(loser[i])\n",
    "    origin_list.append(1-coin_winner)\n",
    "print(\"Result:\",resulting_list)\n",
    "print(\"From lists:\",origin_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Random Click Model #####\n",
    "\n",
    "# Learns parameter\n",
    "def learn_param(data):\n",
    "    \n",
    "    # open file and read\n",
    "    lines=data.readlines()\n",
    "\n",
    "    clicks = 0\n",
    "    documents = 0\n",
    "\n",
    "    # Acquire total amount of queries and clicks\n",
    "    for line in lines:\n",
    "        items = re.split(r'\\t+',line)\n",
    "        if items[2] == \"Q\":\n",
    "            # Per query 10 documents are shown\n",
    "            documents += 10\n",
    "        elif items[2] == \"C\":\n",
    "            clicks += 1\n",
    "    \n",
    "    # Calculate rho\n",
    "    rho = clicks/documents\n",
    "    \n",
    "    return rho\n",
    "\n",
    "# Predicts a click probability\n",
    "def predict_prob(ranking, param):\n",
    "    \n",
    "    # get the click probability for every document in ranking\n",
    "    click_prob = []\n",
    "    for doc in ranking:\n",
    "        click_prob.append(param)\n",
    "        \n",
    "    return click_prob\n",
    "\n",
    "# Decide whether document is clicked on\n",
    "def click_doc(click_prob):\n",
    "    clicked = []\n",
    "    for prob in click_prob:\n",
    "        chance = random.random()\n",
    "        if chance <= prob:\n",
    "            clicked.append(1)\n",
    "        else:\n",
    "            clicked.append(0)\n",
    "    return clicked\n",
    "\n",
    "# get parameter out of data\n",
    "f=open(\"YandexRelPredChallenge.txt\",\"r\")\n",
    "rho = learn_param(f)\n",
    "f.close()\n",
    "\n",
    "# predict probability of clicking\n",
    "click_prob = predict_prob(resulting_list, rho)\n",
    "clicked = click_doc(click_prob)\n",
    "\n",
    "\n",
    "og_shuffle = random.sample(origin_list, len(origin_list))\n",
    "\n",
    "print(origin_list)\n",
    "print(og_shuffle)\n",
    "print(clicked)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### One of the other click models #####\n",
    "\n",
    "# Learns parameter\n",
    "\n",
    "# Predicts a click probability\n",
    "\n",
    "# Decide whether document is clicked on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open(\"YandexRelPredChallenge.txt\",\"r\")\n",
    "lines = f.readlines()\n",
    "\n",
    "previous_session = 0 # Keep track of session number to determine if click is last click.\n",
    "\n",
    "clicks = 0\n",
    "last_clicks = 0\n",
    "\n",
    "lines.reverse() # Reversed order, so it is detectable if a click is last.\n",
    "for line in lines:\n",
    "    items = re.split(r'\\t+',line) #strip tabs\n",
    "    current_session = items[0]\n",
    "    if items[2] == \"C\" and current_session != previous_session:\n",
    "        last_clicks += 1\n",
    "    if items[2] == \"C\":\n",
    "        clicks += 1\n",
    "    previous_session = current_session\n",
    "\n",
    "print(last_clicks/clicks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
