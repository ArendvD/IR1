{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter Notebook contains the first project for Information Retrieval 1 taught at the UvA. Code is made by Oscar Ligthart, Nicole Ferreira Silverio and Arend van Dormalen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER TO THEORETICAL QUESTION 1A\n",
    "\n",
    "The chance of a type 1 error ($\\alpha$) increases each time an experiment is repeated, if it's not corrected. The new $\\alpha$ for _m_ experiments is $1 − (1 − \\alpha)^m ≈ m\\alpha$. This is called the Family-wise error rate.\n",
    "\n",
    "ANSWER TO THEORETICAL QUESTION 1B,\n",
    "\n",
    "The chance of a type 1 error needs to be corrected. This can be done by the Bonferroni correction, which rejects the null hypothesis for any $p_i$ when it it lower than or equal to $\\frac{\\alpha}{m}$.\n",
    "      \n",
    "\n",
    "ANSWER TO THEORETICAL QUESTION 2\n",
    "\n",
    "Assume two ranked lists created by two different rankers. List $l1$ contains documents $d1$, $d2$ and $d3$ in that order. List $l2$ contains documents $d2$, $d3$ and $d4$ in that order. Now assume that the only relevant document is $d3$, which will therefore be clicked on most often. From our judgment, it is obvious that $l2$ is the most relevant list as it has placed $d3$ on a higher position. However, in Team Draft Interleaving, these algorithms will be evaluated as having equal performance.\n",
    "\n",
    "In this situation, $d3$ will always be the third item on the interleaved list. After the first coin flip, $d2$ will be removed from $l1$ as this document has already been supplied by $l2$.  At the second coin flip, $d3$ will be the next document for both lists. This causes the relevance for both lists to be the same, as they now both have the same chance of supplying the only relevant document to the interleaved list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell represents the creation of all possible relevance pairs E and P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import scipy.stats\n",
    "\n",
    "# first get the sequence options\n",
    "relevance = ['N', 'R', 'HR']\n",
    "options = list(itertools.product(relevance, repeat = 5))\n",
    "\n",
    "# create all possible pairs in sequence options\n",
    "pair_index = list(itertools.permutations(range(len(options)), 2))\n",
    "\n",
    "\n",
    "pairs = []\n",
    "\n",
    "for temp_pair in pair_index:\n",
    "    pairs.append([options[temp_pair[0]], options[temp_pair[1]]])    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Offline measures\n",
    "\n",
    "Each cell represents one of the following three offline measures: Average precision, nDCG, ERR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_average_precision(ranking):\n",
    "    rel = 0\n",
    "    AP_numerator = 0\n",
    "    # get amount of relevant documents\n",
    "    for i, doc in enumerate(ranking):\n",
    "        if doc == 'R' or doc == 'HR':\n",
    "            rel += 1\n",
    "            AP_numerator += rel/(i+1)\n",
    "            \n",
    "    return rel, AP_numerator\n",
    "\n",
    "# new dict for average precision for both P and E (key is pair, value is average precisions))\n",
    "AP_delta = {}\n",
    "\n",
    "# new dict for delta measures (AP, nDCG and ERR will be stored here per pair)\n",
    "delta_values = {}\n",
    "\n",
    "# get precision for all pairs\n",
    "for pair in pairs:\n",
    "    # first calculate numerator for average precision for P\n",
    "    P = pair[0]    \n",
    "    P_rel, P_AP_numerator = get_average_precision(P)\n",
    " \n",
    "    # now calculate numerator for average precision for E\n",
    "    E = pair[1]\n",
    "    E_rel, E_AP_numerator = get_average_precision(E)\n",
    "\n",
    "    # get total number of relevant documents returned from query\n",
    "    total_rel = P_rel + E_rel\n",
    "    \n",
    "    # calculate average precision for both P and E\n",
    "    P_AP = P_AP_numerator/total_rel\n",
    "    E_AP = E_AP_numerator/total_rel\n",
    "    \n",
    "    # store results in a dict\n",
    "    AP_delta[(P,E)] = [E_AP - P_AP]\n",
    "    \n",
    "    # store AP delta measures in list format in dict\n",
    "    delta_values[(P,E)] = [E_AP - P_AP]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### nDCG cell #####\n",
    "def get_nDCG(ranking):\n",
    "    DCG = 0\n",
    "    \n",
    "    # loop through ranking\n",
    "    for i, rank in enumerate(ranking):\n",
    "        # decide what the relative rank is\n",
    "        if rank == 'HR':\n",
    "            rel_r = 2\n",
    "        elif rank == 'R':\n",
    "            rel_r = 1\n",
    "        elif rank == 'N':\n",
    "            rel_r = 0\n",
    "        \n",
    "        DCG += (2**rel_r - 1)/(np.log2(1+(i+1)))\n",
    "    \n",
    "    return DCG\n",
    "\n",
    "# new dict for average precision for both P and E (key is pair, value is average precisions))\n",
    "nDCG_delta = {}\n",
    "\n",
    "counter = 0\n",
    "same_counter = 0\n",
    "lower_counter = 0\n",
    "\n",
    "# get nDCG for all pairs\n",
    "for pair in pairs:    \n",
    "    # first for P\n",
    "    P = pair[0]\n",
    "    P_DCG = get_nDCG(P)\n",
    "    \n",
    "    # then for E\n",
    "    E = pair[1]\n",
    "    E_DCG = get_nDCG(E)\n",
    "    \n",
    "    nDCG_delta[(P,E)] = [E_DCG - P_DCG]\n",
    "    \n",
    "    # add nDCG delta measure to dict\n",
    "    delta_values[(P,E)].append(E_DCG - P_DCG)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ERR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_ERR(ranking):\n",
    "    \n",
    "    ERR = 0\n",
    "    p = 1\n",
    "    max_rel = 2\n",
    "    \n",
    "    # loop through ranking\n",
    "    for i, rank in enumerate(ranking):        \n",
    "        # start at second rank\n",
    "        if i != 0:            \n",
    "            # decide what the relative rank is\n",
    "            if rank == 'HR':\n",
    "                rel_r = 2\n",
    "            elif rank == 'R':\n",
    "                rel_r = 1\n",
    "            elif rank == 'N':\n",
    "                rel_r = 0\n",
    "\n",
    "            # Calculate R with the mapping function\n",
    "            R = (2**rel_r - 1)/(2**max_rel)\n",
    "\n",
    "            # Modify ERR value\n",
    "            ERR += p * (R/i)\n",
    "\n",
    "            # Modify p\n",
    "            p = p*(1-R)\n",
    "    \n",
    "    return ERR\n",
    "\n",
    "# new dict for ERR values for both P and E (key is pair, value is ERR value))\n",
    "ERR_delta = {}\n",
    "\n",
    "# get ERR for all pairs\n",
    "for pair in pairs:\n",
    "    \n",
    "    # first for P\n",
    "    P = pair[0]\n",
    "    P_ERR = get_ERR(P)\n",
    "    \n",
    "    # then for E\n",
    "    E = pair[1]\n",
    "    E_ERR = get_ERR(E)\n",
    "    \n",
    "    ERR_delta[(P,E)] = [E_ERR - P_ERR]\n",
    "    \n",
    "    # add ERR delta measures to dict\n",
    "    delta_values[(P,E)].append(E_ERR -  P_ERR)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering and interleaving pairs\n",
    "In the following cells the pairs that hold delta values that are positive are extracted for further use. We extracted the pairs holding a positive delta value for all offline measures. Moreover, we took the mean of delta values from all offline measures and extracted the pairs that had a positive delta value for this mean.\n",
    "Afterwards, we used balance interleaving to create one ranking out of both algorithms for every pair where E outperforms P."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### Filter pairs #####\n",
    "\n",
    "def filter_pairs(pairs_dict):\n",
    "    # this function is used to extract pairs that have a positive delta value for the mean of all offline measures\n",
    "    pairs_list = []\n",
    "    dict_items = pairs_dict.items()\n",
    "    for pair in dict_items:\n",
    "        scores = pair[1]\n",
    "        avg = sum(scores, 0.0)/len(scores)\n",
    "        if avg > 0.0:\n",
    "            pairs_list.append(pair[0])\n",
    "    \n",
    "    return pairs_list\n",
    "\n",
    "def interleaving(pairs):\n",
    "    # this function \n",
    "    all_results = []\n",
    "    all_origins = []\n",
    "    for pair in pairs:\n",
    "\n",
    "        # Flip a coin, assign winning and losing\n",
    "        # P = pair[0], E = pair[1]\n",
    "        coin_winner = random.randint(0,1)\n",
    "        winner = pair[coin_winner]\n",
    "        loser = pair[1 - coin_winner]\n",
    "\n",
    "        # initiate lists\n",
    "        resulting_list = []\n",
    "        origin_list = []\n",
    "\n",
    "        # iterate through lists, fill up results and origin list\n",
    "        for i in range(len(winner)):\n",
    "            resulting_list.append(winner[i])\n",
    "            origin_list.append(coin_winner)\n",
    "            resulting_list.append(loser[i])\n",
    "            origin_list.append(1-coin_winner)\n",
    "\n",
    "        all_results.append(resulting_list)\n",
    "        all_origins.append(origin_list)\n",
    "    \n",
    "    return all_results, all_origins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 58806\n",
      "After: 29403\n",
      "29403\n"
     ]
    }
   ],
   "source": [
    "##### Balanced Interleaving #####\n",
    "\n",
    "print(\"Before:\", len(delta_values.items()))\n",
    "\n",
    "all_pairs = filter_pairs(delta_values)\n",
    "\n",
    "print(\"After:\", len(all_pairs))\n",
    "\n",
    "all_results, all_origins = interleaving(all_pairs)\n",
    "\n",
    "# now get pairs for which delta measure is positive for every offline metric\n",
    "AP_pairs = filter_pairs(AP_delta)\n",
    "DCG_pairs = filter_pairs(nDCG_delta)\n",
    "ERR_pairs = filter_pairs(ERR_delta)\n",
    "\n",
    "# interleave the pairs for which E outperforms P per offline metric\n",
    "AP_results, AP_origins = interleaving(AP_pairs)\n",
    "DCG_results, DCG_origins = interleaving(DCG_pairs)\n",
    "ERR_results, ERR_origins = interleaving(ERR_pairs)\n",
    "\n",
    "print(len(all_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Click Model\n",
    "The following cells represent the random click model and its simulation. Simulation is run for A) every offline measure for which E outperforms P and B) the mean delta values of all offline measures for which E outperforms P."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### Random Click Model #####\n",
    "\n",
    "# Learns parameter\n",
    "def learn_param_RCM(data):\n",
    "    \n",
    "    # open file and read\n",
    "    lines=data.readlines()\n",
    "\n",
    "    clicks = 0\n",
    "    documents = 0\n",
    "\n",
    "    # Acquire total amount of queries and clicks\n",
    "    for line in lines:\n",
    "        items = re.split(r'\\t+',line)\n",
    "        if items[2] == \"Q\":\n",
    "            # Per query 10 documents are shown\n",
    "            documents += 10\n",
    "        elif items[2] == \"C\":\n",
    "            clicks += 1\n",
    "    \n",
    "    # Calculate rho\n",
    "    rho = clicks/documents\n",
    "    \n",
    "    return rho\n",
    "\n",
    "# Predicts a click probability\n",
    "def predict_prob_RCM(ranking, param):\n",
    "    \n",
    "    # get the click probability for every document in ranking\n",
    "    click_prob = []\n",
    "    for doc in ranking:\n",
    "        click_prob.append(param)\n",
    "        \n",
    "    return click_prob\n",
    "\n",
    "# Decide whether document is clicked on\n",
    "def click_doc_RCM(click_prob):\n",
    "    # this function uses the click probability to determine whether a document\n",
    "    # is clicked on or not\n",
    "    clicked = []\n",
    "    for prob in click_prob:\n",
    "        chance = random.random()\n",
    "        if chance <= prob:\n",
    "            clicked.append(1)\n",
    "        else:\n",
    "            clicked.append(0)\n",
    "    return clicked\n",
    "\n",
    "# simulates the model\n",
    "def RCM_simulation(pairs, origins, rho, N):\n",
    "    # the following function represents the simulation of the random click model\n",
    "    #\n",
    "    # the function takes an interleaved ranking and a list which tells which element\n",
    "    # in the ranking comes from which algorithm. Furthermore, parameters rho and N\n",
    "    # are given as input, representing click probability and number of simulations \n",
    "    # respectively.\n",
    "    #\n",
    "    # output consists of a list consisting of N proportions where E\n",
    "    # outperforms P for all pairs\n",
    "    \n",
    "    # initialize a list holding the proportion of wins for E\n",
    "    p_RCM_list = []\n",
    "\n",
    "    # simulate experiment N times\n",
    "    for i in range(N):\n",
    "        # keep track of which algorithm won\n",
    "        E_win = 0\n",
    "        P_win = 0\n",
    "        \n",
    "        # loop through all rankings\n",
    "        for j, ranking in enumerate(pairs):\n",
    "\n",
    "            # predict probability of clicking\n",
    "            click_prob = predict_prob_RCM(ranking, rho)\n",
    "\n",
    "            # get which documents were clicked\n",
    "            clicked = click_doc_RCM(click_prob)\n",
    "\n",
    "            # now shuffle the origin list so documents are picked at random\n",
    "            origin_shuffle = random.sample(origins[j], len(origins[j]))\n",
    "\n",
    "            E_click = 0\n",
    "            P_click = 0\n",
    "            # check whether the clicked documents were produced by E or P\n",
    "            for h, click in enumerate(clicked):\n",
    "                if click == 1 and origin_shuffle[h] == 1:\n",
    "                    E_click += 1\n",
    "                elif click == 1 and origin_shuffle[h] == 0:\n",
    "                    P_click += 1\n",
    "\n",
    "            # determine whether E or P won\n",
    "            if E_click > P_click:\n",
    "                E_win += 1\n",
    "            elif P_click > E_click:\n",
    "                P_win += 1\n",
    "\n",
    "        # proportion of times E won\n",
    "        if (E_win - P_win) == 0:\n",
    "            p = 0.5\n",
    "        else:\n",
    "            p = E_win / (E_win + P_win)\n",
    "        p_RCM_list.append(p)\n",
    "        \n",
    "    return p_RCM_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.506585556423708, 0.5049162011173184, 0.4953897736797988, 0.49522193949674864, 0.4981658514895509, 0.5063760462895343, 0.5040464363453703, 0.49840327189198275, 0.5027328499721138, 0.49974720521319027, 0.5073728050427735, 0.5015904905407668, 0.5010098743267505, 0.49260752688172044, 0.4963499582056283, 0.5001404257709375, 0.4991300443396756, 0.49482922466320084, 0.4996917213160697, 0.5035429085592172, 0.5010330001675135, 0.49710885308482566, 0.4949960643202519, 0.4985109849974715, 0.4921273031825796, 0.49808342728297633, 0.4945244315970871, 0.5008060481405303, 0.49842342342342344, 0.500252851604203, 0.5050036750155481, 0.4998037566582562, 0.49776236294473036, 0.4933526980225673, 0.5000840383214746, 0.5000841987089532, 0.49619431385717483, 0.5012064418382807, 0.4950238965420298, 0.504163853252307, 0.5010046885465506, 0.49330794646357173, 0.5061486864169927, 0.5023886234862793, 0.4934627686437349, 0.49986065436709215, 0.4981269220016774, 0.4977728285077951, 0.5006426376082704, 0.5026148881718037]\n",
      "[0.49908017328348464, 0.494750501356612, 0.4992035868090378, 0.49950137854167886, 0.5041415217134066, 0.49724404831711033, 0.4953491110326151, 0.5026597299351143, 0.4983168960018898, 0.4975513616817965, 0.49762526715744476, 0.499852793970441, 0.5015501608657502, 0.5007941643626096, 0.5038212815990594, 0.5021619380441864, 0.49651087785140446, 0.4942934462877986, 0.49171237777247795, 0.5002915111940298, 0.5013796747490166, 0.49616971125515613, 0.5020619771415106, 0.4988347704497786, 0.49413923750887995, 0.49727649496743637, 0.5027660460412825, 0.5051468007954146, 0.5046375612926094, 0.4982700991027972, 0.5021368772320122, 0.49384098544232924, 0.49874364518202535, 0.5017644982943184, 0.4991785965735743, 0.49655456740679665, 0.5038878416588124, 0.49726711724948575, 0.49666510648256496, 0.5031081398076472, 0.5039563917707052, 0.5040014122631516, 0.5045372050816697, 0.4939491376790412, 0.5013819464863275, 0.49578841962655357, 0.5018243879472694, 0.49280999528524283, 0.49375515494285377, 0.4991731632412001]\n",
      "[0.503754342709851, 0.49854797274656537, 0.500752382544725, 0.4991286750238912, 0.5021087555530563, 0.4998603273925918, 0.5001966181675187, 0.49820062977957713, 0.4977909512890778, 0.5016284815813118, 0.4981816147261232, 0.5006198579961681, 0.50146051005505, 0.5032771273318022, 0.4997764363961547, 0.505880376344086, 0.5019298540023494, 0.4914311400797887, 0.49814481673038, 0.4999162619326746, 0.5011811023622047, 0.5069405574834882, 0.508501294899223, 0.5014243422890018, 0.4984308451019951, 0.5063375214479438, 0.5071468453378001, 0.5004214667041303, 0.5003351206434317, 0.5, 0.49949506283662476, 0.5070391185799343, 0.4992970024183117, 0.5001121453403611, 0.5045009564532463, 0.5022454249466711, 0.5003071767662665, 0.4972942817294282, 0.5057503349709692, 0.5032110347908639, 0.5005853169072969, 0.5015864180350682, 0.4954696381338286, 0.5014886804112129, 0.5011201971546992, 0.5033928975344945, 0.5046949676693843, 0.5027895559027002, 0.5036430893397601, 0.5021625568724373]\n",
      "[0.4946968407917872, 0.5025297953676636, 0.5028810303920461, 0.5019313792319927, 0.49932234018522703, 0.5008328068462466, 0.4997469777902727, 0.5014067071798335, 0.49805754180507855, 0.49814423571061495, 0.4970261923824774, 0.4995480736639928, 0.4974737439682089, 0.4965340909090909, 0.4995169082125604, 0.4992089501638603, 0.494781622234827, 0.4938467645891227, 0.498216812906878, 0.4983277591973244, 0.5046580322653942, 0.498156446763855, 0.5085264290975016, 0.49892033185589274, 0.5020885075637842, 0.500142005112184, 0.495777977932898, 0.5083640487666572, 0.5051499717034522, 0.5087250611038481, 0.4968628115991182, 0.5016601947211435, 0.49771843839783675, 0.499660671869698, 0.5014295516925892, 0.500510783200908, 0.49522517940893934, 0.5003394049100577, 0.5002570987830658, 0.5007937407869373, 0.4962259835315645, 0.5017115472387038, 0.5013050385837494, 0.4982786838986399, 0.5042996152975786, 0.5040022547914318, 0.4958262831359278, 0.5060534057479068, 0.495963872424499, 0.4916467780429594]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.67181103376536544"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### Simulate random click model ######\n",
    "\n",
    "# get parameter out of data\n",
    "f=open(\"YandexRelPredChallenge.txt\",\"r\")\n",
    "rho = learn_param_RCM(f)\n",
    "f.close()\n",
    "\n",
    "# Run N simulations\n",
    "N = 50\n",
    "\n",
    "# get the p for the average of all metrics\n",
    "p_RCM_list = RCM_simulation(all_results, all_origins, rho, N)\n",
    "\n",
    "# get the p for every metric \n",
    "p_AP_RCM_list = RCM_simulation(AP_results, AP_origins, rho, N)\n",
    "p_DCG_RCM_list = RCM_simulation(DCG_results, DCG_origins, rho, N)\n",
    "p_ERR_RCM_list = RCM_simulation(ERR_results, ERR_origins, rho, N)\n",
    "\n",
    "print(p_RCM_list)\n",
    "print(p_AP_RCM_list)\n",
    "print(p_DCG_RCM_list)\n",
    "print(p_ERR_RCM_list)\n",
    "\n",
    "success = 0\n",
    "for p in p_RCM_list:\n",
    "    if p > 0.5:\n",
    "        success += 1\n",
    "scipy.stats.binom_test(success, N, p=0.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Dynamic Bayesian Model\n",
    "The following cells represent the simiple dynamic bayesian model and its simulation. Simulation is run for A) every offline measure for which E outperforms P and B) the mean delta values of all offline measures for which E outperforms P."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### Simple Dynamic Bayesian Model #####\n",
    "\n",
    "# Learns parameter\n",
    "def learn_param_DBM(file):\n",
    "    \n",
    "    lines = file.readlines()\n",
    "\n",
    "    #previous_session = 0 # Keep track of session number to determine if click is last click.\n",
    "    previous_type = \"\"\n",
    "    \n",
    "    clicks = 0\n",
    "    #last_clicks_session = 0\n",
    "    last_clicks_query = 0\n",
    "\n",
    "    lines.reverse() # Reversed order, so it is detectable if a click is last.\n",
    "    for line in lines:\n",
    "        items = re.split(r'\\t+',line) #strip tabs\n",
    "        #current_session = items[0]\n",
    "        current_type = items[2]\n",
    "        #if current_type == \"C\" and current_session != previous_session:\n",
    "            #last_clicks_session += 1\n",
    "        if current_type == \"C\" and previous_type == \"Q\": \n",
    "            last_clicks_query += 1\n",
    "        if current_type == \"C\":\n",
    "            clicks += 1\n",
    "        #previous_session = current_session\n",
    "        previous_type = current_type\n",
    "\n",
    "    sigma = last_clicks_query/clicks\n",
    "    \n",
    "    return sigma\n",
    "        \n",
    "\n",
    "# Predicts a click probability\n",
    "def predict_prob_DBM(rank, sigma):\n",
    "    # for the click probability, we'll need P(A) and P(E)\n",
    "    # first get alpha, which will be set according to the level of relevance of a document\n",
    "    if rank == 'HR':\n",
    "        alpha = 0.8\n",
    "    elif rank == 'R':\n",
    "        alpha = 0.2\n",
    "    elif rank == 'N':\n",
    "        alpha = 0 \n",
    "    \n",
    "    # check if user will click on the document (depending on alpha)\n",
    "    x = random.random()\n",
    "    if x <= alpha:\n",
    "        P_A = 1\n",
    "    else:\n",
    "        P_A = 0\n",
    "            \n",
    "    # since we are using a simple DBM, gamma will always be one    \n",
    "    gamma = 1\n",
    "    \n",
    "    return P_A, gamma  \n",
    "       \n",
    "        \n",
    "# Decide which documents are clicked\n",
    "def click_doc_DBM(ranking, sigma):\n",
    "    # this function takes a ranking list and a value for the parameter sigma as input and uses\n",
    "    # these to determine which documents in the ranking list are clicked on\n",
    "    \n",
    "    # set P(E) to 1 (first snippet is always read)\n",
    "    P_E = 1\n",
    "    \n",
    "    clicked = []\n",
    "    \n",
    "    # run through the ranking to decide whether a document will be clicked or not\n",
    "    for rank in ranking:\n",
    "        P_A, gamma = predict_prob_DBM(rank, sigma)\n",
    "        \n",
    "        # based on probability, set click to 1 or 0\n",
    "        if P_A == 1 and P_E == 1:\n",
    "            P_C = 1\n",
    "        else:\n",
    "            P_C = 0\n",
    "     \n",
    "        clicked.append(P_C)\n",
    "        \n",
    "        # if user has clicked, check if user is satisfied\n",
    "        if P_C == 1:\n",
    "            # now check if user is satisfied\n",
    "            x = random.random()\n",
    "            if x <= sigma:\n",
    "                # if satisfied, user will not read any more snippets (thus click nothing)\n",
    "                P_E = 0\n",
    "            else:\n",
    "                # if user is not satisfied, user will read next snippet (thus possibly click)\n",
    "                P_E = 1 \n",
    "        \n",
    "    return clicked       \n",
    "\n",
    "def DBM_simulation(pairs, origins, sigma, N):\n",
    "    # the following function represents the simulation of the dynamic bayesion model\n",
    "    #\n",
    "    # the function takes an interleaved ranking and a list which tells which element\n",
    "    # in the ranking comes from which algorithm. Furthermore, parameters sigma and N\n",
    "    # are given as input, representing satisfaction and number of simulations \n",
    "    # respectively.\n",
    "    #\n",
    "    # output consists of a list consisting of N proportions where E\n",
    "    # outperforms P for all pairs\n",
    "    \n",
    "    p_DBM_list = []\n",
    "    # simulate experiment N times\n",
    "    for i in range(N):\n",
    "\n",
    "        # keep track of which algorithm won\n",
    "        E_win = 0\n",
    "        P_win = 0\n",
    "        # loop through all rankings\n",
    "        for j, ranking in enumerate(pairs):\n",
    "\n",
    "            # get which documents were clicked\n",
    "            clicked = click_doc_DBM(ranking, sigma)\n",
    "\n",
    "            E_click = 0\n",
    "            P_click = 0\n",
    "\n",
    "            current_origin = origins[j]\n",
    "\n",
    "            # check whether the clicked documents were produced by E or P\n",
    "            for h, click in enumerate(clicked):\n",
    "                if click == 1 and current_origin[h] == 1:\n",
    "                    E_click += 1\n",
    "                elif click == 1 and current_origin[h] == 0:\n",
    "                    P_click += 1\n",
    "\n",
    "            # determine whether E or P won\n",
    "            if E_click > P_click:\n",
    "                E_win += 1\n",
    "            elif P_click > E_click:\n",
    "                P_win += 1\n",
    "       \n",
    "        \n",
    "        # proportion of times E won\n",
    "        if (E_win - P_win) == 0:\n",
    "            p = 0.5\n",
    "        else:\n",
    "            p = E_win / (E_win + P_win)\n",
    "            \n",
    "        p_DBM_list.append(p)\n",
    "        \n",
    "    return p_DBM_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7485529451821586, 0.7436641351651164, 0.7445673056397558, 0.7480625079405412, 0.7477947413061917, 0.7469690546841882, 0.7463290061715259, 0.7432168070085906, 0.7516389953171563, 0.7514524948735475, 0.745123868610037, 0.7481840193704601, 0.7497245529282143, 0.750511073253833, 0.7456916827025871, 0.747238796496128, 0.7471723786036227, 0.7479546616669508, 0.7503509891512444, 0.7507628411595185, 0.7520275147552121, 0.7517848036715962, 0.741968514015103, 0.7468316873648964, 0.7505321413367391, 0.746540853890746, 0.7486424571525538, 0.7510346887400264, 0.7505853305521264, 0.747102613992048, 0.7469587409612931, 0.746468085106383, 0.7515238740264139, 0.7445797445797446, 0.744691693562086, 0.74462388440289, 0.7448996867857445, 0.7479232553236348, 0.7489933454838299, 0.7491072946777759, 0.7494711904560454, 0.7480539367901655, 0.7471850435521563, 0.7497873426335488, 0.7447115180804612, 0.7496918957970337, 0.7514056909183847, 0.7464698877169105, 0.7466076821642775, 0.7466180399474153]\n",
      "[0.6726964134173031, 0.6691235593674618, 0.6675142755174875, 0.6734020250680227, 0.6683351955307263, 0.6722113502935421, 0.6710620739146035, 0.6713033366132928, 0.6715129283349736, 0.6715832627779511, 0.6674709562109026, 0.6683891660727014, 0.6686865966424275, 0.6692783688732582, 0.675163223325284, 0.6677538983959609, 0.6711538461538461, 0.6701406046448947, 0.6729974856321839, 0.6709205300968275, 0.6690564189339627, 0.6684049631361266, 0.6642443156486848, 0.6737955976246819, 0.6713853276353277, 0.666592228673515, 0.6702627691481265, 0.6671594982078853, 0.6707040121120363, 0.6700873851669281, 0.6716944084965862, 0.6699233630618922, 0.6653046722330787, 0.6695020931682552, 0.6684137436724454, 0.6717304856798177, 0.6680316923350841, 0.6725402504472272, 0.6703611011798355, 0.670024625027983, 0.6707000089629829, 0.6707300736771601, 0.6717302209550963, 0.6683956358433196, 0.6717090584560464, 0.6702630405706643, 0.6688877957157551, 0.671631806627124, 0.6648034700174396, 0.663778932871296]\n",
      "[0.753013593229033, 0.7543284978942443, 0.755181071534959, 0.7537699085055913, 0.7531446540880503, 0.7490142875312672, 0.7535714285714286, 0.756381204839882, 0.747689030883919, 0.7472994811601599, 0.7475390359809911, 0.756258514986376, 0.7527817888388686, 0.7514502644599897, 0.7464722883373003, 0.752539790044023, 0.7489678655032985, 0.7539959190613841, 0.7548150025342119, 0.7556300097544425, 0.7552158732862131, 0.7516164709885996, 0.7510414010031454, 0.7504145584421106, 0.7535898419191274, 0.7571452875127594, 0.7580802718199193, 0.7573338993844194, 0.7529522104275909, 0.7528528401136894, 0.7529536311666314, 0.7515966670896248, 0.7533716230589236, 0.756317842605156, 0.7516595744680851, 0.7498937526561836, 0.7514730193717943, 0.7581043137922233, 0.7520184544405998, 0.7485544217687075, 0.7511780938229675, 0.7513200476920456, 0.7504464665362701, 0.75333048676345, 0.7524752475247525, 0.7484215432857324, 0.753011278995531, 0.7509328358208955, 0.755259586019681, 0.7530439947392983]\n",
      "[0.6580101470461777, 0.6601666523494545, 0.6578901933701657, 0.6579399141630902, 0.6596885590493758, 0.6563113424938124, 0.6577259224178758, 0.6544592847910383, 0.6567356955267577, 0.6556581490229761, 0.6570012925463162, 0.6593093934560503, 0.6602657522503215, 0.655148642826368, 0.6564372225335114, 0.657426508509541, 0.6580866580866581, 0.6581042123832882, 0.6601118760757315, 0.6598146081881383, 0.6529197712701438, 0.6565193156969515, 0.6591499307479224, 0.657230002577541, 0.6586165257892013, 0.6559037806612924, 0.6583523928710137, 0.6654922012632665, 0.6607748080140718, 0.6566436583261432, 0.6597640778370931, 0.6612910143684323, 0.6596250216001383, 0.6582873404622284, 0.659803583735355, 0.6572644795115449, 0.6572846967407727, 0.6544588038298055, 0.6594918690419704, 0.6619906192176944, 0.6553312384314063, 0.6568210155208737, 0.6589602813759973, 0.6531931397052486, 0.6641050959515734, 0.6576051779935275, 0.6561814191660571, 0.6556861731903716, 0.6577917329777625, 0.6577068639256838]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.7763568394002505e-15"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Simulate dynamic bayesian model #####\n",
    "\n",
    "# get parameter out of data\n",
    "f=open(\"YandexRelPredChallenge.txt\",\"r\")\n",
    "sigma = learn_param_DBM(f)\n",
    "f.close()\n",
    "\n",
    "# run N simulations\n",
    "N = 50\n",
    "\n",
    "# get the p for the average of all metrics\n",
    "p_DBM_list = DBM_simulation(all_results, all_origins, sigma, N)\n",
    "\n",
    "# get the p for every metric \n",
    "p_AP_DBM_list = DBM_simulation(AP_results, AP_origins, sigma, N)\n",
    "p_DCG_DBM_list = DBM_simulation(DCG_results, DCG_origins, sigma, N)\n",
    "p_ERR_DBM_list = DBM_simulation(ERR_results, ERR_origins, sigma, N)\n",
    "\n",
    "print(p_DBM_list)\n",
    "print(p_AP_DBM_list)\n",
    "print(p_DCG_DBM_list)\n",
    "print(p_ERR_DBM_list)\n",
    "\n",
    "success = 0\n",
    "for p in p_DBM_list:\n",
    "    if p > 0.5:\n",
    "        success += 1\n",
    "scipy.stats.binom_test(success, N, p=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell shows the effect of different values for delta on proportion of wins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nArU/mAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b847aa7f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create new dict with all values for which delta is positive\n",
    "pairs_dict = {}\n",
    "for key, value in delta_values.items():\n",
    "    avg = sum(value, 0.0)/len(value)\n",
    "    if avg > 0.0:\n",
    "        pairs_dict[key] = avg\n",
    "\n",
    "keys = sorted(pairs_dict, key=pairs_dict.get)\n",
    "\n",
    "index = round(len(pairs_dict)/10)\n",
    "\n",
    "##### set parameters #######\n",
    "\n",
    "# get rho out of data\n",
    "f=open(\"YandexRelPredChallenge.txt\",\"r\")\n",
    "rho = learn_param_RCM(f)\n",
    "f.close()\n",
    "\n",
    "# get sigma out of data                     \n",
    "f=open(\"YandexRelPredChallenge.txt\",\"r\")\n",
    "sigma = learn_param_DBM(f)\n",
    "f.close()\n",
    "\n",
    "\n",
    "# take first 10 % of the sorted dictionary to represent the low delta values\n",
    "low_deltas = keys[:index]\n",
    "\n",
    "# take last 10 % of the sorted dictionary to represent the high delta values\n",
    "high_deltas = keys[-index:]\n",
    "\n",
    "# interleave both pair lists\n",
    "low_delta_results, low_delta_origins = interleaving(low_deltas)\n",
    "high_delta_results, high_delta_origins = interleaving(high_deltas)\n",
    "\n",
    "# run the random click model on both delta's\n",
    "p_RCM_ld = RCM_simulation(low_delta_results, low_delta_origins, rho, N)\n",
    "p_RCM_hd = RCM_simulation(high_delta_results, high_delta_origins, rho, N)\n",
    "\n",
    "# run the dynamic bayesion model on both delta's\n",
    "p_DBM_ld = DBM_simulation(low_delta_results, low_delta_origins, sigma, N)\n",
    "p_DBM_hd = DBM_simulation(high_delta_results, high_delta_origins, sigma, N)\n",
    "\n",
    "# run statistical tests to find significant differences\n",
    "scipy.stats.ttest_ind(p_DBM_ld, p_DBM_hd)\n",
    "\n",
    "####### CREATE PLOT ########\n",
    "\n",
    "multiple_bars = plt.figure()\n",
    "\n",
    "x = [0.25,0.8]\n",
    "names = ['RCM', 'DBM']\n",
    "\n",
    "bars_lowdelta = [sum(p_RCM_ld)/len(p_RCM_ld), sum(p_DBM_ld)/len(p_DBM_ld)]\n",
    "bars_highdelta = [sum(p_RCM_hd)/len(p_RCM_hd), sum(p_DBM_hd)/len(p_DBM_hd)]\n",
    "\n",
    "ax = plt.subplot(111)\n",
    "ax.bar(x[0]-0.1, bars_lowdelta[0] ,width=0.2,color='b',align='center', label = 'low delta')\n",
    "ax.bar(x[0]+0.1, bars_lowdelta[1] ,width=0.2,color='r',align='center', label = 'high delta')\n",
    "ax.bar(x[1]-0.1, bars_highdelta[0] ,width=0.2,color='b',align='center')\n",
    "ax.bar(x[1]+0.1, bars_highdelta[1] ,width=0.2,color='r',align='center')\n",
    "ax.set_xticks([x[0],x[1]])\n",
    "ax.set_xticklabels(names)\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles, labels)\n",
    "ax.set_title('Effect of delta values on click models')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure ?: Effect of delta values on click models. This figure shows the proportion of times where algorithm E provided more links that were clicked than algorithm P in a ranking. The blue bars represent 10% of the delta values where E outperforms P  just slightly (lowest delta values). The red bars represent 10% of the delta values where E outperforms P more clearly (highest delta values). The delta values where calculated by taking the mean of all results of the offline measures per pair. \n",
    "\n",
    "From this figure can be concluded that the models as well as the offline metrics seem to work. Pairs are extracted based on their delta measure. Pairs are only considered if E outperforms P (resulting in extraction of all positive delta values). The higher the delta value, the more E outperforms P, meaning the more relevant documents will be provided by E in comparison with P. We thus expected to find differences in only our dynamic bayesian model based on these delta values. For the random click model we did not expect to find any differences, since the probability of clicking on a document does not depend in any way on the relevance of a document. Thus, the manner in which E outperform P (meaning having more relevant documents in an interleaved ranking) will not have any effect on what is clicked.\n",
    "For the dynamic bayesian model (DBM), we did expect to find differences caused by the difference in delta values. We based this expectation on the fact that in a DBM, relevance has an impact on click probability. Therefore, algorithms that provide more relevant documents in comparison to other algorithms in a ranking will be more likely to win (provide more documents that are clicked on). This effect can be found in the figure above, which shows that within the DBM, E wins by a larger margin if it provides more relevant documents in comparison to P (thus having a larger delta value for the offline measures) . If E outperforms P just slightly (by having a low delta value), E is not more likely to provide more documents that were clicked on, since the algorithms provide roughly the same amount of relevant documents. These results confirm that our offline measures calculate their delta in such a way that it has a high value for pairs where E outperforms P by a large margin and a low valuje for pairs where E outperforms P by a small margin. Moreover, we can conclude that our click models seem to work based on the assumptions that we made beforehand and the results shown in this figure. The RCM is not affected by difference in relevance of provided documents, while the DBM shows that an algorithm that provides relatively more relevant documents is more likely to win (provide more documents that area clicked) than an algorithm that provides relatively less relevant documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### PLOT OVER THE AVERAGE OF ALL METRICS #####\n",
    "\n",
    "# average over all metrics and standard deviation for random click model\n",
    "avg_ALL_RCM = statistics.mean(p_RCM_list)\n",
    "stdev_ALL_RCM = statistics.pstdev(p_RCM_list)\n",
    "\n",
    "# average over all metrics and standard deviation for dynamic bayesian model\n",
    "avg_ALL_DBM = statistics.mean(p_DBM_list)\n",
    "stdev_ALL_DBM = statistics.pstdev(p_DBM_list)\n",
    "\n",
    "# plot bar graph over all metrics, RCM compared to DBM\n",
    "ax = plt.gca()\n",
    "\n",
    "x = (1, 1.75)\n",
    "y = (avg_ALL_RCM, avg_ALL_DBM)\n",
    "z = (stdev_ALL_RCM, stdev_ALL_DBM)\n",
    "names = ('RCM', 'DBM')\n",
    "clr = ('tomato', 'dodgerblue')\n",
    "for i in range(len(x)):\n",
    "    plt.bar(x[i], y[i], width=0.5, color = clr[i], yerr = z[i], align=\"center\")\n",
    "\n",
    "ind = (1,1.75)\n",
    "plt.xticks(ind, x)\n",
    "ax.set_xticklabels(names)\n",
    "\n",
    "leg = ax.legend(names, loc = 'upper right')\n",
    "ax.set_title('Average over all metrics for both the Random Click Model (RCM) and the Dynamic Bayesian Model')\n",
    "\n",
    "# Get the bounding box of the original legend\n",
    "bb = leg.get_bbox_to_anchor().inverse_transformed(ax.transAxes)\n",
    "\n",
    "# Change the location of the legend. \n",
    "xOffset = 0.25\n",
    "bb.x0 += xOffset\n",
    "bb.x1 += xOffset\n",
    "leg.set_bbox_to_anchor(bb, transform = ax.transAxes)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### PLOTS FOR EACH METRIC #####\n",
    "\n",
    "# average and standard deviation per metric for random click model\n",
    "avg_AP_RCM = statistics.mean(p_AP_RCM_list)\n",
    "stdev_AP_RCM = statistics.pstdev(p_AP_RCM_list)\n",
    "\n",
    "avg_DCG_RCM = statistics.mean(p_DCG_RCM_list)\n",
    "stdev_DCG_RCM = statistics.pstdev(p_DCG_RCM_list)\n",
    "\n",
    "avg_ERR_RCM = statistics.mean(p_ERR_RCM_list)\n",
    "stdev_ERR_RCM = statistics.pstdev(p_ERR_RCM_list)\n",
    "\n",
    "# average and standard deviation per metric for random click model\n",
    "avg_AP_DBM = statistics.mean(p_AP_DBM_list)\n",
    "stdev_AP_DBM = statistics.pstdev(p_AP_DBM_list)\n",
    "\n",
    "avg_DCG_DBM = statistics.mean(p_DCG_DBM_list)\n",
    "stdev_DCG_DBM = statistics.pstdev(p_DCG_DBM_list)\n",
    "\n",
    "avg_ERR_DBM = statistics.mean(p_ERR_DBM_list)\n",
    "stdev_ERR_DBM = statistics.pstdev(p_ERR_DBM_list)\n",
    "\n",
    "\n",
    "# plot bar graph over all metrics, RCM compared to DBM\n",
    "ax = plt.gca()\n",
    "\n",
    "#x = range(1, 7)\n",
    "x = (2,2,2,4,4,4)\n",
    "y = (avg_AP_RCM, avg_DCG_RCM, avg_ERR_RCM, avg_AP_DBM, avg_DCG_DBM, avg_ERR_DBM)\n",
    "z = (stdev_AP_RCM, stdev_DCG_RCM, stdev_ERR_RCM, stdev_AP_DBM, stdev_DCG_DBM, stdev_ERR_DBM)\n",
    "names_leg = ('AP', 'DCG', 'ERR', 'AP', 'DCG', 'ERR')\n",
    "names = ('RCM', 'DBM')\n",
    "clr = ('r', 'tomato', 'lightsalmon', 'b', 'dodgerblue', 'lightskyblue')\n",
    "sides = (0.5, 0, -0.5, 0.5, 0, -0.5)\n",
    "for i in range(len(x)):\n",
    "    plt.bar(x[i]-sides[i], y[i], width=0.5, color = clr[i], yerr = z[i], align=\"center\")\n",
    "\n",
    "ind = (2,4)\n",
    "plt.xticks(ind, x)\n",
    "ax.set_xticklabels(names)\n",
    "\n",
    "leg = ax.legend(names_leg, loc = 'upper right')\n",
    "ax.set_title('Average per metric for both the Random Click Model (RCM) and the Dynamic Bayesian Model')\n",
    "\n",
    "# Get the bounding box of the original legend\n",
    "bb = leg.get_bbox_to_anchor().inverse_transformed(ax.transAxes)\n",
    "\n",
    "# Change the location of the legend. \n",
    "xOffset = 0.25\n",
    "bb.x0 += xOffset\n",
    "bb.x1 += xOffset\n",
    "leg.set_bbox_to_anchor(bb, transform = ax.transAxes)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, you can find the percentages of co-occurent pairs between the offline evaluation measures. We find that a high percentage of overlapping pairs seems to correlate to a higher performace of this evaluation measure. We assume that pairs found by only a single measure have a higher chance of being misclassified and thus decrease performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Check percentages of overlapping pairs between offline measures #####,\n",
    "\n",
    "print(\"AP:\",len(AP_pairs))\n",
    "print(\"DCG:\",len(DCG_pairs))\n",
    "print(\"ERR:\",len(ERR_pairs))\n",
    "\n",
    "print(\"---\")\n",
    "\n",
    "print(\"AP in DCG:\", len(list(set(AP_pairs).intersection(DCG_pairs)))/len(AP_pairs))\n",
    "print(\"AP in ERR:\", len(list(set(AP_pairs).intersection(ERR_pairs)))/len(AP_pairs))\n",
    "print(\"DCG in AP:\", len(list(set(DCG_pairs).intersection(AP_pairs)))/len(DCG_pairs))\n",
    "print(\"DCG in ERR:\", len(list(set(DCG_pairs).intersection(ERR_pairs)))/len(DCG_pairs))\n",
    "print(\"ERR in AP:\", len(list(set(ERR_pairs).intersection(AP_pairs)))/len(ERR_pairs))\n",
    "print(\"ERR in DCG:\", len(list(set(ERR_pairs).intersection(DCG_pairs)))/len(ERR_pairs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Through our test of the evaluation measures, we find that ERR has the worst performance. A likely cause of this relatively poor performance is the assumption of independence between queries and documents. ERR is an algorithm designed specifically to tackle the downsides of this assumption and is thus likely to perform better in a real-world application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
