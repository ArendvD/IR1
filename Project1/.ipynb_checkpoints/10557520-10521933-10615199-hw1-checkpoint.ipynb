{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter Notebook contains the first project for Information Retrieval 1 taught at the UvA. Code is made by Oscar Ligthart, Nicole Ferreira Silverio and Arend van Dormalen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER TO THEORETICAL QUESTION 1A\n",
    "\n",
    "The chance of a type 1 error ($\\alpha$) increases each time an experiment is repeated, if it's not corrected. The new $\\alpha$ for _m_ experiments is $1 − (1 − \\alpha)^m ≈ m\\alpha$.\n",
    "\n",
    "ANSWER TO THEORETICAL QUESTION 2\n",
    "\n",
    "Assume two ranked lists created by two different rankers. List $l1$ contains documents $d1$, $d2$ and $d3$ in that order. List $l2$ contains documents $d2$, $d3$ and $d4$ in that order. Now assume that the only relevant document is $d3$, which will therefore be clicked on most often. From our judgment, it is obvious that $l2$ is the most relevant list as it has placed $d3$ on a higher position. However, in Team Draft Interleaving, these algorithms will be evaluated as having equal performance.\n",
    "\n",
    "In this situation, $d3$ will always be the third item on the interleaved list. After the first coin flip, $d2$ will be removed from $l1$ as this document has already been supplied by $l2$.  At the second coin flip, $d3$ will be the next document for both lists. This causes the relevance for both lists to be the same, as they now both have the same chance of supplying the only relevant document to the interleaved list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "\n",
    "# first get the sequence options\n",
    "relevance = ['N', 'R', 'HR']\n",
    "options = list(itertools.product(relevance, repeat = 5))\n",
    "\n",
    "# create all possible pairs in sequence options\n",
    "pair_index = list(itertools.permutations(range(len(options)), 2))\n",
    "\n",
    "\n",
    "pairs = []\n",
    "\n",
    "for temp_pair in pair_index:\n",
    "    pairs.append([options[temp_pair[0]], options[temp_pair[1]]])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58806\n"
     ]
    }
   ],
   "source": [
    "def get_average_precision(ranking):\n",
    "    rel = 0\n",
    "    AP_numerator = 0\n",
    "    # get amount of relevant documents\n",
    "    for i, doc in enumerate(ranking):\n",
    "        if doc == 'R' or doc == 'HR':\n",
    "            rel += 1\n",
    "            AP_numerator += rel/(i+1)\n",
    "            \n",
    "    return rel, AP_numerator\n",
    "\n",
    "# new dict for average precision for both P and E (key is pair, value is average precisions))\n",
    "AP_delta = {}\n",
    "\n",
    "# new dict for delta measures (AP, nDCG and ERR will be stored here per pair)\n",
    "delta_values = {}\n",
    "\n",
    "# get precision for all pairs\n",
    "for pair in pairs:\n",
    "    # first calculate numerator for average precision for P\n",
    "    P = pair[0]    \n",
    "    P_rel, P_AP_numerator = get_average_precision(P)\n",
    " \n",
    "    # now calculate numerator for average precision for E\n",
    "    E = pair[1]\n",
    "    E_rel, E_AP_numerator = get_average_precision(E)\n",
    "\n",
    "    # get total number of relevant documents returned from query\n",
    "    total_rel = P_rel + E_rel\n",
    "    \n",
    "    # calculate average precision for both P and E\n",
    "    P_AP = P_AP_numerator/total_rel\n",
    "    E_AP = E_AP_numerator/total_rel\n",
    "    \n",
    "    # store results in a dict\n",
    "    AP_delta[(P,E)] = E_AP - P_AP\n",
    "    \n",
    "    # store AP delta measures in list format in dict\n",
    "    delta_values[(P,E)] = [E_AP - P_AP]\n",
    "\n",
    "#for value in AP_results.values():\n",
    "#    print(value)\n",
    "    \n",
    "#print(len(AP_results.values()))\n",
    "print(len(pairs))\n",
    "\n",
    "# ####### NOW GET DELTA MEASURES #########\n",
    "# AP_delta_values = []\n",
    "# for key, value in AP_results.items():\n",
    "#     if value[1] > value[0]:\n",
    "#         delta_value = value[1] - value[0]\n",
    "#         AP_delta_values.append(delta_value)\n",
    "\n",
    "# print(len(AP_delta_values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### nDCG cell #####\n",
    "def get_nDCG(ranking):\n",
    "    DCG = 0\n",
    "    \n",
    "    # loop through ranking\n",
    "    for i, rank in enumerate(ranking):\n",
    "        # decide what the relative rank is\n",
    "        if rank == 'HR':\n",
    "            rel_r = 2\n",
    "        elif rank == 'R':\n",
    "            rel_r = 1\n",
    "        elif rank == 'N':\n",
    "            rel_r = 0\n",
    "        \n",
    "        DCG += (2**rel_r - 1)/(np.log2(1+(i+1)))\n",
    "    \n",
    "    return DCG\n",
    "\n",
    "# new dict for average precision for both P and E (key is pair, value is average precisions))\n",
    "nDCG_delta = {}\n",
    "\n",
    "counter = 0\n",
    "same_counter = 0\n",
    "lower_counter = 0\n",
    "\n",
    "# get nDCG for all pairs\n",
    "for pair in pairs:    \n",
    "    # first for P\n",
    "    P = pair[0]\n",
    "    P_DCG = get_nDCG(P)\n",
    "    \n",
    "    # then for E\n",
    "    E = pair[1]\n",
    "    E_DCG = get_nDCG(E)\n",
    "    \n",
    "    nDCG_delta[(P,E)] = E_DCG - P_DCG\n",
    "    \n",
    "    # add nDCG delta measure to dict\n",
    "    delta_values[(P,E)].append(E_DCG - P_DCG)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### ERR cell #####\n",
    "\n",
    "def get_ERR(ranking):\n",
    "    \n",
    "    ERR = 0\n",
    "    p = 1\n",
    "    max_rel = 2\n",
    "    \n",
    "    # loop through ranking\n",
    "    for i, rank in enumerate(ranking):\n",
    "        \n",
    "        # start at second rank\n",
    "        if i != 0:\n",
    "            \n",
    "            # decide what the relative rank is\n",
    "            if rank == 'HR':\n",
    "                rel_r = 2\n",
    "            elif rank == 'R':\n",
    "                rel_r = 1\n",
    "            elif rank == 'N':\n",
    "                rel_r = 0\n",
    "\n",
    "            # Calculate R with the mapping function\n",
    "            R = (2**rel_r - 1)/(2**max_rel)\n",
    "\n",
    "            # Modify ERR value\n",
    "            ERR += p * (R/i)\n",
    "\n",
    "            # Modify p\n",
    "            p = p*(1-R)\n",
    "    \n",
    "    return ERR\n",
    "\n",
    "# new dict for ERR values for both P and E (key is pair, value is ERR value))\n",
    "ERR_delta = {}\n",
    "\n",
    "# get ERR for all pairs\n",
    "for pair in pairs:\n",
    "    \n",
    "    # first for P\n",
    "    P = pair[0]\n",
    "    P_ERR = get_ERR(P)\n",
    "    \n",
    "    # then for E\n",
    "    E = pair[1]\n",
    "    E_ERR = get_ERR(E)\n",
    "    \n",
    "    ERR_delta[(P,E)] = E_ERR - P_ERR\n",
    "    \n",
    "    # add ERR delta measures to dict\n",
    "    delta_values[(P,E)].append(E_ERR -  P_ERR)\n",
    "    \n",
    "# ##### NOW GET THE DELTA MEASURES #####\n",
    "# ERR_delta_values = []\n",
    "# for key, value in ERR_results.items():\n",
    "#     if value[1] > value[0]:\n",
    "#         delta_value = value[1] - value[0]\n",
    "#         ERR_delta_values.append(delta_value)\n",
    "\n",
    "# print(len(ERR_delta_values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### Filter pairs #####\n",
    "\n",
    "def filter_all_pairs(pairs_dict):\n",
    "    \n",
    "    pairs_list = []\n",
    "    dict_items = pairs_dict.items()\n",
    "    for pair in dict_items:\n",
    "        scores = pair[1]\n",
    "        avg = sum(scores, 0.0)/len(scores)\n",
    "        if avg > 0.0:\n",
    "            pairs_list.append(pair[0])\n",
    "    \n",
    "    return pairs_list\n",
    "\n",
    "def filter_metric_pairs(pairs_dict):\n",
    "    \n",
    "    pairs_list = []\n",
    "    dict_items = pairs_dict.items()\n",
    "    for pair in dict_items:\n",
    "        scores = pair[1]\n",
    "        if scores > 0.0:\n",
    "            pairs_list.append(pair[0])\n",
    "    \n",
    "    return pairs_list\n",
    "\n",
    "\n",
    "# Iterate through pairs\n",
    "def interleaving(pairs):\n",
    "    all_results = []\n",
    "    all_origins = []\n",
    "    for pair in pairs:\n",
    "\n",
    "        # Flip a coin, assign winning and losing\n",
    "        # P = pair[0], E = pair[1]\n",
    "        coin_winner = random.randint(0,1)\n",
    "        winner = pair[coin_winner]\n",
    "        loser = pair[1 - coin_winner]\n",
    "\n",
    "        # initiate lists\n",
    "        resulting_list = []\n",
    "        origin_list = []\n",
    "\n",
    "        # iterate through lists, fill up results and origin list\n",
    "        for i in range(len(winner)):\n",
    "            resulting_list.append(winner[i])\n",
    "            origin_list.append(coin_winner)\n",
    "            resulting_list.append(loser[i])\n",
    "            origin_list.append(1-coin_winner)\n",
    "\n",
    "        all_results.append(resulting_list)\n",
    "        all_origins.append(origin_list)\n",
    "    \n",
    "    return all_results, all_origins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: 58806\n",
      "after: 29403\n",
      "29403\n",
      "29403\n"
     ]
    }
   ],
   "source": [
    "##### Balanced Interleaving #####\n",
    "\n",
    "print(\"before:\", len(delta_values.items()))\n",
    "\n",
    "all_pairs = filter_all_pairs(delta_values)\n",
    "\n",
    "print(\"after:\", len(all_pairs))\n",
    "\n",
    "all_results, all_origins = interleaving(all_pairs)\n",
    "print(len(all_results))\n",
    "# now get pairs for which delta measure is positive for every offline metric\n",
    "AP_pairs = filter_metric_pairs(AP_delta)\n",
    "DCG_pairs = filter_metric_pairs(nDCG_delta)\n",
    "ERR_pairs = filter_metric_pairs(ERR_delta)\n",
    "\n",
    "# interleave the pairs for which E outperforms P per offline metric\n",
    "AP_results, AP_origins = interleaving(AP_pairs)\n",
    "DCG_results, DCG_origins = interleaving(DCG_pairs)\n",
    "ERR_results, ERR_origins = interleaving(ERR_pairs)\n",
    "\n",
    "print(len(all_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### Random Click Model #####\n",
    "\n",
    "# Learns parameter\n",
    "def learn_param_RCM(data):\n",
    "    \n",
    "    # open file and read\n",
    "    lines=data.readlines()\n",
    "\n",
    "    clicks = 0\n",
    "    documents = 0\n",
    "\n",
    "    # Acquire total amount of queries and clicks\n",
    "    for line in lines:\n",
    "        items = re.split(r'\\t+',line)\n",
    "        if items[2] == \"Q\":\n",
    "            # Per query 10 documents are shown\n",
    "            documents += 10\n",
    "        elif items[2] == \"C\":\n",
    "            clicks += 1\n",
    "    \n",
    "    # Calculate rho\n",
    "    rho = clicks/documents\n",
    "    \n",
    "    return rho\n",
    "\n",
    "# Predicts a click probability\n",
    "def predict_prob_RCM(ranking, param):\n",
    "    \n",
    "    # get the click probability for every document in ranking\n",
    "    click_prob = []\n",
    "    for doc in ranking:\n",
    "        click_prob.append(param)\n",
    "        \n",
    "    return click_prob\n",
    "\n",
    "# Decide whether document is clicked on\n",
    "def click_doc_RCM(click_prob):\n",
    "    clicked = []\n",
    "    for prob in click_prob:\n",
    "        chance = random.random()\n",
    "        if chance <= prob:\n",
    "            clicked.append(1)\n",
    "        else:\n",
    "            clicked.append(0)\n",
    "    return clicked\n",
    "\n",
    "def RCM_simulation(pairs, origins, rho):\n",
    "\n",
    "    N = 50\n",
    "    p_RCM_list = []\n",
    "\n",
    "    # simulate experiment N times\n",
    "    for i in range(N):\n",
    "        # keep track of which algorithm won\n",
    "        E_win = 0\n",
    "        P_win = 0\n",
    "        # loop through all rankings\n",
    "        for j, ranking in enumerate(pairs):\n",
    "\n",
    "            # predict probability of clicking\n",
    "            click_prob = predict_prob_RCM(ranking, rho)\n",
    "\n",
    "            # get which documents were clicked\n",
    "            clicked = click_doc_RCM(click_prob)\n",
    "\n",
    "            # now shuffle the origin list so documents are picked at random\n",
    "            origin_shuffle = random.sample(origins[j], len(origins[j]))\n",
    "\n",
    "            E_click = 0\n",
    "            P_click = 0\n",
    "            # check whether the clicked documents were produced by E or P\n",
    "            for h, click in enumerate(clicked):\n",
    "                if click == 1 and origin_shuffle[h] == 1:\n",
    "                    E_click += 1\n",
    "                elif click == 1 and origin_shuffle[h] == 0:\n",
    "                    P_click += 1\n",
    "\n",
    "            # determine whether E or P won\n",
    "            if E_click > P_click:\n",
    "                E_win += 1\n",
    "            elif P_click > E_click:\n",
    "                P_win += 1\n",
    "\n",
    "        # proportion of times E won\n",
    "        p = E_win / (E_win + P_win)\n",
    "        p_RCM_list.append(p)\n",
    "        \n",
    "    return p_RCM_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Simulate random click model ######\n",
    "\n",
    "# get parameter out of data\n",
    "f=open(\"YandexRelPredChallenge.txt\",\"r\")\n",
    "rho = learn_param_RCM(f)\n",
    "f.close()\n",
    "\n",
    "# get the p for the average of all metrics\n",
    "p_RCM_list = RCM_simulation(all_results, all_origins, rho)\n",
    "\n",
    "# get the p for every metric \n",
    "p_AP_RCM_list = RCM_simulation(AP_results, AP_origins, rho)\n",
    "p_DCG_RCM_list = RCM_simulation(DCG_results, DCG_origins, rho)\n",
    "p_ERR_RCM_list = RCM_simulation(ERR_results, ERR_origins, rho)\n",
    "\n",
    "print(p_RCM_list)\n",
    "print(p_AP_RCM_list)\n",
    "print(p_DCG_RCM_list)\n",
    "print(p_ERR_RCM_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Simple Dynamic Bayesian Model #####\n",
    "\n",
    "# Learns parameter\n",
    "def learn_param_DBM(file):\n",
    "    \n",
    "    lines = file.readlines()\n",
    "\n",
    "    #previous_session = 0 # Keep track of session number to determine if click is last click.\n",
    "    previous_type = \"\"\n",
    "    \n",
    "    clicks = 0\n",
    "    #last_clicks_session = 0\n",
    "    last_clicks_query = 0\n",
    "\n",
    "    lines.reverse() # Reversed order, so it is detectable if a click is last.\n",
    "    for line in lines:\n",
    "        items = re.split(r'\\t+',line) #strip tabs\n",
    "        #current_session = items[0]\n",
    "        current_type = items[2]\n",
    "        #if current_type == \"C\" and current_session != previous_session:\n",
    "            #last_clicks_session += 1\n",
    "        if current_type == \"C\" and previous_type == \"Q\": \n",
    "            last_clicks_query += 1\n",
    "        if current_type == \"C\":\n",
    "            clicks += 1\n",
    "        #previous_session = current_session\n",
    "        previous_type = current_type\n",
    "\n",
    "    sigma = last_clicks_query/clicks\n",
    "    \n",
    "    return sigma\n",
    "        \n",
    "\n",
    "# Predicts a click probability\n",
    "def predict_prob_DBM(rank, sigma):\n",
    "    # for the click probability, we'll need P(A) and P(E)\n",
    "\n",
    "    # first get alpha, which will be set according to the level of relevance of a document\n",
    "    if rank == 'HR':\n",
    "        alpha = 0.9\n",
    "    elif rank == 'R':\n",
    "        alpha = 0.3\n",
    "    elif rank == 'N':\n",
    "        alpha = 0 \n",
    "    \n",
    "    # check if user will click on the document (depending on alpha)\n",
    "    x = random.random()\n",
    "    if x <= alpha:\n",
    "        P_A = 1\n",
    "    else:\n",
    "        P_A = 0\n",
    "            \n",
    "    # since we are using a simple DBM, gamma will always be one    \n",
    "    gamma = 1\n",
    "    \n",
    "    return P_A, gamma  \n",
    "       \n",
    "        \n",
    "# Decide which documents are clicked\n",
    "def click_doc_DBM(ranking, sigma):\n",
    "    # this function takes a ranking list and a value for the parameter sigma as input and uses\n",
    "    # these to determine which documents in the ranking list are clicked on\n",
    "    \n",
    "    # set P(E) to 1 (first snippet is always read)\n",
    "    P_E = 1\n",
    "    \n",
    "    clicked = []\n",
    "    \n",
    "    # run through the ranking to decide whether a document will be clicked or not\n",
    "    for rank in ranking:\n",
    "        P_A, gamma = predict_prob_DBM(rank, sigma)\n",
    "        \n",
    "        # based on probability, set click to 1 or 0\n",
    "        if P_A == 1 and P_E == 1:\n",
    "            P_C = 1\n",
    "        else:\n",
    "            P_C = 0\n",
    "     \n",
    "        clicked.append(P_C)\n",
    "        \n",
    "        # if user has clicked, check if user is satisfied\n",
    "        if P_C == 1:\n",
    "            # now check if user is satisfied\n",
    "            x = random.random()\n",
    "            if x <= sigma:\n",
    "                # if satisfied, user will not read any more snippets (thus click nothing)\n",
    "                P_E = 0\n",
    "            else:\n",
    "                # if user is not satisfied, user will read next snippet (thus possibly click)\n",
    "                P_E = 1 \n",
    "        \n",
    "    return clicked       \n",
    "\n",
    "def DBM_simulation(pairs, origins, sigma):\n",
    "    N = 50\n",
    "    p_DBM_list = []\n",
    "    # simulate experiment N times\n",
    "    for i in range(N):\n",
    "\n",
    "        # keep track of which algorithm won\n",
    "        E_win = 0\n",
    "        P_win = 0\n",
    "        # loop through all rankings\n",
    "        for j, ranking in enumerate(pairs):\n",
    "\n",
    "            # get which documents were clicked\n",
    "            clicked = click_doc_DBM(ranking, sigma)\n",
    "\n",
    "            E_click = 0\n",
    "            P_click = 0\n",
    "\n",
    "            current_origin = origins[j]\n",
    "\n",
    "            # check whether the clicked documents were produced by E or P\n",
    "            for h, click in enumerate(clicked):\n",
    "                if click == 1 and current_origin[h] == 1:\n",
    "                    E_click += 1\n",
    "                elif click == 1 and current_origin[h] == 0:\n",
    "                    P_click += 1\n",
    "\n",
    "            # determine whether E or P won\n",
    "            if E_click > P_click:\n",
    "                E_win += 1\n",
    "            elif P_click > E_click:\n",
    "                P_win += 1\n",
    "        #print(E_win, P_win)\n",
    "        # proportion of times E won\n",
    "        p = E_win / (E_win + P_win)\n",
    "        p_DBM_list.append(p)\n",
    "    return p_DBM_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Simulate dynamic bayesian model #####\n",
    "\n",
    "# get parameter out of data\n",
    "f=open(\"YandexRelPredChallenge.txt\",\"r\")\n",
    "sigma = learn_param_DBM(f)\n",
    "f.close()\n",
    "\n",
    "print(len(all_results))\n",
    "# get the p for the average of all metrics\n",
    "p_DBM_list = DBM_simulation(all_results, all_origins, sigma)\n",
    "\n",
    "\n",
    "# get the p for every metric \n",
    "p_AP_DBM_list = DBM_simulation(AP_results, AP_origins, sigma)\n",
    "p_DCG_DBM_list = DBM_simulation(DCG_results, DCG_origins, sigma)\n",
    "p_ERR_DBM_list = DBM_simulation(ERR_results, ERR_origins, sigma)\n",
    "\n",
    "print(p_DBM_list)\n",
    "print(p_AP_DBM_list)\n",
    "print(p_DCG_DBM_list)\n",
    "print(p_ERR_DBM_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5180102915951973, 0.5260504201680672, 0.48717948717948717, 0.5109612141652614, 0.5122749590834698, 0.5205930807248764, 0.5141955835962145, 0.5189003436426117, 0.4899328859060403, 0.4991735537190083, 0.5086505190311419, 0.5227272727272727, 0.4773109243697479, 0.46905537459283386, 0.4966442953020134, 0.5073170731707317, 0.4992, 0.4772727272727273, 0.4914383561643836, 0.48833333333333334, 0.506514657980456, 0.46991869918699186, 0.4973821989528796, 0.521311475409836, 0.532695374800638, 0.49155405405405406, 0.5101088646967341, 0.4782608695652174, 0.5399673735725938, 0.46192052980132453, 0.5082236842105263, 0.5023255813953489, 0.4906937394247039, 0.4958263772954925, 0.5008156606851549, 0.49916805324459235, 0.506514657980456, 0.48519736842105265, 0.4850498338870432, 0.47572815533980584, 0.469721767594108, 0.4868421052631579, 0.4950980392156863, 0.504, 0.48464163822525597, 0.50920245398773, 0.5040128410914928, 0.4725085910652921, 0.49225473321858865, 0.5318791946308725]\n",
      "[0.5577557755775577, 0.521594684385382, 0.5370675453047776, 0.4559068219633943, 0.5139573070607554, 0.5126050420168067, 0.48657187993680884, 0.4889240506329114, 0.48205928237129486, 0.5295081967213114, 0.48983050847457626, 0.4889240506329114, 0.5279187817258884, 0.49592169657422513, 0.48214285714285715, 0.5094339622641509, 0.5159128978224455, 0.5225375626043406, 0.49185667752442996, 0.5478260869565217, 0.48049921996879874, 0.49169435215946844, 0.5040387722132472, 0.5302013422818792, 0.505654281098546, 0.5285481239804242, 0.47619047619047616, 0.5364667747163695, 0.49246231155778897, 0.459546925566343, 0.509090909090909, 0.5090609555189456, 0.5434412265758092, 0.49837662337662336, 0.4576271186440678, 0.5098684210526315, 0.48450244698205547, 0.49335548172757476, 0.5214521452145214, 0.4695222405271829, 0.4852459016393443, 0.4565587734241908, 0.4826388888888889, 0.4921875, 0.49748743718592964, 0.4967532467532468, 0.4728434504792332, 0.5382113821138211, 0.4868421052631579, 0.5073891625615764]\n",
      "[0.5201612903225806, 0.5134770889487871, 0.5238726790450928, 0.508819538670285, 0.5114401076716016, 0.5169606512890095, 0.5177398160315374, 0.5251989389920424, 0.5194109772423026, 0.523680649526387, 0.5099337748344371, 0.545816733067729, 0.5263870094722598, 0.5405405405405406, 0.511968085106383, 0.5224274406332454, 0.5229357798165137, 0.5067385444743935, 0.5561497326203209, 0.5220883534136547, 0.527369826435247, 0.5259562841530054, 0.4746666666666667, 0.5285714285714286, 0.5537414965986395, 0.5196211096075778, 0.5263157894736842, 0.5142083897158322, 0.503242542153048, 0.5794392523364486, 0.5135135135135135, 0.5238095238095238, 0.49389416553595655, 0.5529891304347826, 0.496617050067659, 0.49595687331536387, 0.5340453938584779, 0.5275167785234899, 0.5106382978723404, 0.5100671140939598, 0.5, 0.5190217391304348, 0.508724832214765, 0.5278514588859416, 0.5629228687415426, 0.5129958960328317, 0.4909596662030598, 0.5162162162162162, 0.5, 0.548]\n",
      "[0.9711637487126673, 0.968421052631579, 0.9780334728033473, 0.9761658031088083, 0.9679089026915114, 0.976890756302521, 0.9779411764705882, 0.9716386554621849, 0.9737670514165793, 0.9718456725755996, 0.9778481012658228, 0.9716684155299056, 0.9663865546218487, 0.9633507853403142, 0.9808510638297873, 0.9789473684210527, 0.9647302904564315, 0.9768177028451, 0.9671957671957672, 0.9769150052465897, 0.9686847599164927, 0.9653725078698846, 0.9592050209205021, 0.9842105263157894, 0.9671261930010604, 0.9663865546218487, 0.9708636836628513, 0.9620653319283456, 0.9681528662420382, 0.9708636836628513, 0.9674711437565582, 0.9739854318418314, 0.9707419017763845, 0.9749216300940439, 0.9684542586750788, 0.9735729386892178, 0.9725738396624473, 0.9705573080967402, 0.9802083333333333, 0.9665621734587252, 0.9696335078534032, 0.9737394957983193, 0.9725738396624473, 0.9716981132075472, 0.9652265542676501, 0.9727463312368972, 0.9759162303664921, 0.9758403361344538, 0.9653361344537815, 0.9706806282722513]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-159.43026416126315, pvalue=3.4857082019902508e-120)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Effect of different values for delta on \n",
    "# create new dict with all values for which delta is positive\n",
    "pairs_dict = {}\n",
    "for key, value in delta_values.items():\n",
    "    avg = sum(value, 0.0)/len(value)\n",
    "    if avg > 0.0:\n",
    "        pairs_dict[key] = avg\n",
    "\n",
    "keys = sorted(pairs_dict, key=pairs_dict.get)\n",
    "\n",
    "low_deltas = keys[:1000]\n",
    "high_deltas = keys[-1000:]\n",
    "\n",
    "low_delta_results, low_delta_origins = interleaving(low_deltas)\n",
    "high_delta_results, high_delta_origins = interleaving(high_deltas)\n",
    "\n",
    "# get parameter out of data\n",
    "f=open(\"YandexRelPredChallenge.txt\",\"r\")\n",
    "rho = learn_param_RCM(f)\n",
    "f.close()\n",
    "\n",
    "f=open(\"YandexRelPredChallenge.txt\",\"r\")\n",
    "sigma = learn_param_DBM(f)\n",
    "f.close()\n",
    "\n",
    "p_RCM_ld = RCM_simulation(low_delta_results, low_delta_origins, rho)\n",
    "p_RCM_hd = RCM_simulation(high_delta_results, high_delta_origins, rho)\n",
    "\n",
    "p_DBM_ld = DBM_simulation(low_delta_results, low_delta_origins, sigma)\n",
    "p_DBM_hd = DBM_simulation(high_delta_results, high_delta_origins, sigma)\n",
    "\n",
    "print(p_RCM_ld)\n",
    "print(p_RCM_hd)\n",
    "\n",
    "print(p_DBM_ld)\n",
    "print(p_DBM_hd)\n",
    "\n",
    "import scipy.stats \n",
    "\n",
    "scipy.stats.ttest_ind(p_DBM_ld, p_DBM_hd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
